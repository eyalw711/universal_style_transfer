\hspace{0.5cm} Existing stylization methods can be classified into two categories: global and local. Global methods \cite{bib12, bib13} achieve stylization through matching the means and variances of pixel colors \cite{bib12}. Local methods \cite{bib14} stylize images through finding dense correspondences between the content and style photos based on either low-level or high-level features. These approaches are slow in practice. Also, they are often developed for specific scenarios. Therefore these methods do not scale to the setting of arbitrary style images well. Gatys et al. \cite{bib7, bib8} showed remarkable results by using the VGG-19 deep neural network for style transfer. The major step in the algorithm is to solve an optimization problem of matching the Gram matrices of deep features extracted from the content and style images. A number of methods have been developed \cite{bib15, bib16, bib17} to further improve its stylization performance and speed. However, these methods do not aim to preserve photorealism. Their approach was taken up by various follow-up papers that, among other things, proposed different  ways  to  represent  the  style  within  the  neural  network. Li et al. \cite{bib15} suggested an approach to preserve local patterns of the style image. Instead of using a global representation of the style, computed as Gram matrix. Nikulin et al. \cite{bib18} tried the style transfer algorithm by Gatys et al. on other nets than VGG and proposed several variations in the way the style of the image is represented  to archive different goals like illumination or season transfer. However, this method is developed for specific scenarios which cannot be scaled to the setting of arbitrary style images. This project is an extension of UST \cite{bib11}, which is closest to a related work \cite{bib19}, directly adjusts the content feature to match the mean and variance of the style feature. However, the generalization ability of the learned models on unseen styles is still limited. UST is also closely related to \cite{bib15}, where content feature in a particular (higher) layer is adaptively instance normalized by the mean and variance of style feature. This step can be viewed as a sub-optimal approximation of the WCT operation, thereby leading to less effective results on both training and unseen styles. Moreover, the  encoder-decoder network in \cite{bib11} is trained solely based on image reconstruction, while \cite{bib15} requires learning such a module particularly for stylization task. Different from the existing methods, the approach in \cite{bib11} is to perform style transfer efficiently in a feed-forward manner while achieving generalization and visual quality on arbitrary styles. 